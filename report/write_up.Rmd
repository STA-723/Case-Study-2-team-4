---
title: "Patterns among Airbnb Listings in NYC"
author: "Frances Hung, Yunran Chen, Keru Wu"
fontsize: "11pt"
output:
  pdf_document: 
        latex_engine: xelatex
  html_document:
    keep_md: yes
    fig_caption: TRUE
header-includes:  
  \usepackage{float} 
  \floatplacement{figure}{H}
urlcolor: blue
linkcolor: blue
bibliography: bibliography.bib
link-citations: true

geometry: margin=1.2in 
---
\fontsize{10}{11}
\selectfont

##### Abstract


#### 1. Introduction


#### 2. Materials and Methods

##### 2.1 Exploratory Data Analysis

##### 2.2 Missing data manipulation

Cite MICE: [@buuren2010mice] 

##### 2.3 Multilevel Conditional Autoregressive (CAR) Model

Cite CARBayes: [@lee2013carbayes]

##### 2.4 Text Analysis

To carry out text analysis on names of listings, we consider using text mining methods including Porter's stemmer algorithm [@porter2001snowball], wordcloud, Latent Dirichlet Allocation [@blei2003latent], etc. We first preprocess these names by transforming them to lower case and removing non-informative characters (e.g. punctuations, stopwords, whitespace, numbers). Then we use Porter's stemmer algorithm for word normalization, which allows us to extract all the common roots of informative words. Based on the result, we further execute word frequency analysis for different boroughs, and use wordcloud to display frequent words. Moreover, we implement LDA to build up a Bayesian generative model, assigning each word a weight of related topics (e.g. adjectives, locations). Features obtained from LDA will be included in our multilevel CAR regression model. 

#### 3. Results

##### 3.1 Exploratory Data Analysis

We obtain an intuitive understanding of the data based on plots of price, popularity and traffic (Figs \ref{} ). Most high-priced listings are located in Manhattan, while some of them also lie in Brooklyn. Similar pattern is discovered for traffic. (Polularity?) In addition, EDA plots for room type (Fig \ref{}) demonstrate that it matters for price but not for popularity. We can also see the heterogeneity of room type across boroughs/neighborhoods. In addition, wordcloud (Fig \ref{}) suggests some high-frequency words in high-priced listings: luxury, manhattan, apartment, etc. 

##### 3.2 Main Results

According to model coefficient estimation (Fig \ref{fig:car1-sum}), our multilevel CAR model on price demonstrates the following patterns. Numbers in brackets are median of corresponding coefficients. For room type, entire room (0) is more expensive than private ones (-0.7) and shared ones (-1.1), with shared room being the cheapest. Manhattan (0.57) stands out to be the most luxurious borough, and Bronx (0) has the lowest price. Availability (0.12) is positively related to price while reviews per month (-0.0) is negatively related. In addition, more strict requirement on minimum nights results in lower price, which aligns with our common sense. And longer distance to metro stations also reduces the price (-0.005).  

Model on popularity (\ref{fig:car1-sum}) has some similarity but is different as follows. Compared to other four boroughs, Queens borough (0.13) has the highest average reviews. Availability still has a positive effect (0.15) while price (-0.12) leads to a negetive influence. Moreover, metro distance is no longer significant for predicting popularity. 

Heterogeneity across neighbourhoods is shown in Fig \ref{fig:car1-plot} and \ref{fig:car2-plot}. According to Fig \ref{fig:car1-plot}, most neighbourhoods in Manhattan have higher average price, and their confidence interval is also narrower than others. Among all neighbourhoods, "Midtown South" in Manhattan turns out to be the most luxurious one, while "New Dorp-Midland Beach" in Staten Island becomes the one with lowest price. On the other hand, \ref{fig:car2-plot} indicates that "East Elmhurst" in Queen is the most popular neighbourhood, which makes sense since LaGuardia Airport is located here, and "Co-op City" is the most unpopular one. If we condsider top 20 neighbourhoods for price and popularity seperately, they have only one intersection at "Yorkville" in Manhattan.

Our text analysis (Fig \ref{fig:wordcloud1}, \ref{fig:wordcloud2}) indicates some critical words: luxury, manhattan, beautiful (Note that we use stemming algorithm so we get stem of words rather than words themselves). We further carry out LDA to find latent topics in listing names. We choose 4 topics which is not too complicated and has a reasonable result (Fig \ref{fig:LDA}). The 4 topics can be categorized as adjectives, locations, Brooklyn related and Manhattan related. If we further add these 4 topics into our model (4 indicators), we conclude that Brooklyn and Manhattan has a positive significant coefficient, while the other two is significantly negative. 


##### 3.3 Answers to Questions

##### 3.4 Sensitivity Analysis


#### 4. Discussion


```{r, echo=F, include=F}

library(sf)
library(dplyr)
library(tidyr)
library(ggplot2)

load("resultdataset 1.rdata")
adj = st_touches(p, sparse=FALSE)
adj2 = matrix(as.numeric(adj), 195, 195)
adj[adj==TRUE]=1

#corrplot::corrplot(adj,method="color",type="full",tl.col="black",cl.pos = "n")

res_dat=res_dat[res_dat$price!=0,]
res_dat=dplyr::select(as.data.frame(res_dat), -geometry)%>%
  mutate(host_id=as.factor(host_id),night=minimum_nights)
res_dat$night=cut(res_dat$night,breaks = c(0,3, 7, 14, 21,28,Inf), right = TRUE)

res_dat = res_dat %>% mutate(ind_area = as.integer(res_dat$ntaname))



dat = res_dat
dat = dat[, !names(dat) %in% c('id', 'host_name','last_review')]
dat$reviews_per_month[is.na(dat$reviews_per_month)] = 0
dat = dat %>% filter(price > 0)
dat = dat %>% filter(!is.na(dat$ind_area))

dat$nata_droped = droplevels(dat$ntaname)
dat$ind_area = as.integer(dat$nata_droped)
which(levels(dat$ntaname) %in% setdiff(levels(dat$ntaname), dat$ntaname))
# 1, 72, 135, 149
adjj = adj2[-c(1,72,135,149), -c(1,72,135,149)]


dat$availability_365 = scale(dat$availability_365)


dat$minimum_nights = as.factor(dat$minimum_nights)




dat$topic1 = grepl("apart", dat$name) | grepl("bedroom", dat$name) | grepl("studio", dat$name) | grepl("east", dat$name) | grepl("spacious", dat$name) | grepl("cozi", dat$name) | grepl("villag", dat$name) | grepl("heart", dat$name) | grepl("bright", dat$name) | grepl("west", dat$name)

dat$topic2 = grepl("brooklyn", dat$name) | grepl("williamsburg", dat$name) | grepl("beauti", dat$name) | grepl("loft", dat$name) | grepl("home", dat$name) | grepl("new", dat$name) | grepl("locat", dat$name) | grepl("great", dat$name) | grepl("brownston", dat$name) | grepl("garden", dat$name) | grepl("west", dat$name)

dat$topic3 = grepl("room", dat$name) | grepl("privat", dat$name) | grepl("park", dat$name) | grepl("near", dat$name) | grepl("cozi", dat$name) | grepl("sunni", dat$name) | grepl("bed", dat$name) | grepl("central", dat$name) | grepl("bath", dat$name) | grepl("close", dat$name) 

dat$topic4 = grepl("apt", dat$name) | grepl("bedroom", dat$name) | grepl("manhattan", dat$name) | grepl("nyc", dat$name) | grepl("luxuri", dat$name) | grepl("min", dat$name) | grepl("midtown", dat$name) | grepl("one", dat$name) | grepl("large", dat$name) | grepl("view", dat$name) 




```



```{r CARBayes Model, echo=F, include=F} 

library(CARBayes)
s =S.CARmultilevel(formula=log(price) ~  room_type + neighbourhood_group + availability_365 + log(1 + reviews_per_month) + night + metrodist + topic1 + topic2 + topic3 + topic4,
                family = 'gaussian', data = dat, ind.area=dat$ind_area,
                W=adjj, burnin=100, n.sample=200, thin = 3)

s2 = S.CARmultilevel(formula=log(1+reviews_per_month) ~  room_type + neighbourhood_group + availability_365 + log(price) + night + metrodist + topic1 + topic2 + topic3 + topic4,
                family = 'gaussian', data = dat, ind.area=dat$ind_area,
                W=adjj, burnin=100, n.sample=200, thin = 3)
```


```{r Price CAR, echo=FALSE,cache=TRUE, fig.width = 3.4,fig.cap="\\label{fig:car1-sum} CAR Model on price - Model Summary"}
print(s$summary.results)
```

```{r Reviews CAR, echo=FALSE,cache=TRUE, fig.width = 3.4,fig.cap="\\label{fig:car2-sum} CAR Model on popularity - Model Summary"}
print(s2$summary.results)
```

```{r, echo=F, include=F}

s =S.CARmultilevel(formula=log(price) ~  room_type  + availability_365 + log(1 + reviews_per_month) + night + metrodist + topic1 + topic2 + topic3 + topic4,
                family = 'gaussian', data = dat, ind.area=dat$ind_area,
                W=adjj, burnin=100, n.sample=200, thin = 3)

s2 = S.CARmultilevel(formula=log(1+reviews_per_month) ~  room_type  + availability_365 + log(price) + night + metrodist + topic1 + topic2 + topic3 + topic4,
                family = 'gaussian', data = dat, ind.area=dat$ind_area,
                W=adjj, burnin=100, n.sample=200, thin = 3)
ss = s$samples

phidf = as.data.frame(ss$phi)
colnames(phidf) = 1:191
phidf = phidf %>% gather()


Man = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Manhattan"]))
Bky = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Brooklyn"]))
Que = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Queens"]))
SI = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Staten Island"]))
Bnx = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Bronx"]))

phidf$borough = rep('0', dim(phidf)[1])
phidf$borough[phidf$key %in% Man] = 'Manhattan'
phidf$borough[phidf$key %in% Que] = 'Queen'
phidf$borough[phidf$key %in% SI] = 'Staten Island'
phidf$borough[phidf$key %in% Bnx] = 'Bronx'
phidf$borough[phidf$key %in% Bky] = 'Brooklyn'
```

```{r Price CAR plot, echo=FALSE,cache=TRUE, fig.width = 8,fig.cap="\\label{fig:car1-plot} CAR Model on price - Neighbourhoods"}
library(ggplot2)
ggplot(phidf, aes(x = borough, y = value, fill = key))+
  geom_boxplot(show.legend = FALSE, lwd= 0.1, outlier.size=0.1)+
  theme(axis.text.x = element_text(hjust = 1, size=10))

```

```{r, echo=F, include=F}

ss = s2$samples

phidf = as.data.frame(ss$phi)
colnames(phidf) = 1:191
phidf = phidf %>% gather()


Man = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Manhattan"]))
Bky = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Brooklyn"]))
Que = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Queens"]))
SI = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Staten Island"]))
Bnx = which(levels(dat$nata_droped) %in% unique(dat$nata_droped[dat$neighbourhood_group=="Bronx"]))

phidf$borough = rep('0', dim(phidf)[1])
phidf$borough[phidf$key %in% Man] = 'Manhattan'
phidf$borough[phidf$key %in% Que] = 'Queen'
phidf$borough[phidf$key %in% SI] = 'Staten Island'
phidf$borough[phidf$key %in% Bnx] = 'Bronx'
phidf$borough[phidf$key %in% Bky] = 'Brooklyn'
```

```{r Pop CAR plot, echo=FALSE,cache=TRUE, fig.width = 8,fig.cap="\\label{fig:car2-plot} CAR Model on popularity - Neighbourhoods"}
library(ggplot2)
ggplot(phidf, aes(x = borough, y = value, fill = key))+
  geom_boxplot(show.legend = FALSE, lwd= 0.1, outlier.size=0.1)+
  theme(axis.text.x = element_text(hjust = 1, size=10))

```



```{r Wordcloud1, echo=FALSE,cache=TRUE, fig.width = 5,fig.cap="\\label{fig:wordcloud1} Wordcloud for listings with price > 2000", warning=FALSE}
Names = data.frame(name = dat$name[dat$price>1000])
library(tm)
text_corpus <- VCorpus(VectorSource(Names$name))

text_corpus_clean <- tm_map(text_corpus, content_transformer(tolower))
text_corpus_clean <- tm_map(text_corpus_clean, stemDocument)
text_corpus_clean <- tm_map(text_corpus_clean, removeNumbers)
text_corpus_clean <- tm_map(text_corpus_clean, removeWords, stopwords())
text_corpus_clean <- tm_map(text_corpus_clean, removePunctuation)
text_corpus_clean <- tm_map(text_corpus_clean, stripWhitespace)

library(wordcloud)
wordcloud(text_corpus_clean, min.freq = 8, random.order = FALSE,
          colors=brewer.pal(8, "Dark2"))
```



```{r Wordcloud2, echo=FALSE,cache=TRUE, fig.width = 5,fig.cap="\\label{fig:wordcloud2} Wordcloud for listings", warning=FALSE}
Names = data.frame(name = dat$name)
library(tm)
text_corpus <- VCorpus(VectorSource(Names$name))

text_corpus_clean <- tm_map(text_corpus, content_transformer(tolower))
text_corpus_clean <- tm_map(text_corpus_clean, stemDocument)
text_corpus_clean <- tm_map(text_corpus_clean, removeNumbers)
text_corpus_clean <- tm_map(text_corpus_clean, removeWords, stopwords())
text_corpus_clean <- tm_map(text_corpus_clean, removePunctuation)
text_corpus_clean <- tm_map(text_corpus_clean, stripWhitespace)

library(wordcloud)
wordcloud(text_corpus_clean, min.freq = 10, random.order = FALSE,
          colors=brewer.pal(8, "Dark2"))
```

```{r LDA, eval = FALSE, echo=FALSE,cache=TRUE, , warning=FALSE}
text_dtm <- DocumentTermMatrix(text_corpus_clean)
text_dtm

library(topicmodels)

rowTotals <- apply(text_dtm , 1, sum) #Find the sum of words in each Document
dtm.new   <- text_dtm[rowTotals> 0, ] 

text_lda <- LDA(dtm.new, k = 4, method = "VEM", control = NULL)
library(tidytext)
text_topics <- tidy(text_lda, matrix = "beta")
text_topics

library(ggplot2)
text_top_terms <- text_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

text_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

```

```{r pressure, echo=FALSE, fig.cap="\\label{fig:LDA} LDA: Top 10 words in each topic", out.width = '100%'}
knitr::include_graphics("LDA.jpeg")
```
