---
title: "eda_yc"
author: "YunranChen"
date: "1/24/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(naniar)
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(purrr)
library(lme4)
library(jpeg)
library(ggpubr)
library(grid)
library(ggmosaic)
library(stringr)
```


```{r}
data = read.csv('AB_NYC_2019.csv', na.strings = c("", "NA"))
dat=data
gg_miss_upset(dat)
nrow(dat)
dat%>%filter(is.na(reviews_per_month),number_of_reviews!=0)

```

- can exist diff listing same host.
- `availability` cannot be used as a measurement for popularity 35% 0's; what does it mean? -> use # of reviews / avg per month
- delete the one price==0 (11)
- term: short-term, middle-term, long-term: minimum night<=7 or 30 ? -> cut the minimum night - not linear for sure
- 0-inflation of number of reviews

## availability

```{r}
install.packages("lubridate")

library("lubridate")
dat%>%filter(availability_365==0)%>%pull(last_review)%>%as.character()%>%date()%>%hist()
dat
dat%>%filter(price==0)%>%nrow()
dat$host_id%>%unique()%>%length()
nrow(dat)
17533/nrow(dat)
dat=data%>%mutate(avail_0=if_else(availability_365==0,TRUE,FALSE))
dat=dat%>%mutate(term=if_else(minimum_nights<=7,"short",if_else(minimum_nights<=45,"middle","long")))
#dat%>%filter(minimum_nights>3,availability_365==0,number_of_reviews==0)

ggplot(data=dat,aes(x=log(price),fill=avail_0))+geom_density(alpha=0.5)
ggplot(data=dat,aes(x=log(1+number_of_reviews),fill=avail_0))+geom_density(alpha=0.5)
```

## minimum nights

```{r}
#ids=dat%>%filter(price==0)%>%pull(host_id)
#dat%>%filter(host_id%in%ids)
quantile(dat$minimum_nights,0.99)
mean(dat$minimum_nights<=30)
dat%>%ggplot(data=.,aes(x=log(price),fill=term))+geom_density(alpha=0.5)
dat%>%ggplot(data=.,aes(x=term,y=log(1+number_of_reviews)))+geom_boxplot(alpha=0.5)
dat%>%ggplot(data=.,aes(x=term,y=log(price)))+geom_boxplot(alpha=0.5)
```

## (ii) heterogeneity across boroughs and neighborhood

- traffic: # of listing / area of the neighborhood ?
- price: group mean of the neighborhood

```{r}
order_nei=dat%>%group_by(neighbourhood_group,neighbourhood)%>%summarise()%>%pull(neighbourhood)%>%as.character()
dat=dat%>%mutate(neighbourhood=factor(neighbourhood,levels = order_nei))
dat%>%ggplot(data=.,aes(x=neighbourhood,y=log(price)))+geom_boxplot()
dat%>%ggplot(data=.,aes(x=neighbourhood_group,y=log(price)))+geom_boxplot()
dat%>%ggplot(data=.,aes(fill=neighbourhood_group,x=log(1+reviews_per_month)))+geom_density(alpha=0.5)
w
dat%>%ggplot(data=.,aes(x=neighbourhood,fill=neighbourhood_group))+geom_bar()
dat%>%ggplot(data=.,aes(x=neighbourhood_group,fill=neighbourhood_group))+geom_bar()
dat%>%group_by(neighbourhood_group,neighbourhood)%>%summarise(count=n())%>%arrange(desc(count))%>%head(5)
```

## room type

```{r}
dat%>%ggplot(data=.,aes(x=room_type,y=log(price)))+geom_boxplot()
dat%>%ggplot(data=.)+geom_mosaic(aes(x=product(room_type,neighbourhood_group),fill=room_type))
```

## maps

```{r message=FALSE, warning=FALSE}
library("ggmap")
ny.map=get_map(location = c(left=-74.2445,right=-73.71298, bottom= 40.49975,top=40.9131),color = "bw",maptype = "toner",source = "stamen")
ggmap(ny.map)+
  stat_density2d(data = dat,
                 aes(x = longitude, y = latitude,fill = ..level.., alpha = ..level..), 
                 geom = "polygon") + 
  scale_fill_gradient(low = "green", high = "red") + 
  scale_alpha(range = c(0, 0.75), guide = FALSE)

img = readJPEG("New_York_City_.jpg")
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

ggplot(dat, aes(x=longitude, y = latitude, color = log(1+price)))+
  annotation_custom(rasterGrob(img, 
                               width = unit(1,"npc"), 
                               height = unit(1,"npc")), 
                    -74.258, -73.69, 40.49,40.92) + 
  geom_point(cex = 0.4,alpha=0.5) +
  scale_colour_gradientn(colors = jet.colors(7), limits = c(3,7)) 

ggplot(dat, aes(x=longitude, y = latitude, color = availability_365))+
  annotation_custom(rasterGrob(img, 
                               width = unit(1,"npc"), 
                               height = unit(1,"npc")), 
                    -74.258, -73.69, 40.49,40.92) + 
  geom_point(cex = 0.4,alpha=0.5) +
  scale_colour_gradient(low = 'red', high = 'grey') 

```

## words

- location
- adj such as: cozy, ... -- use abbr.

```{r}
library(tidytext)
library("textdata")
words=dat$name%>%
  str_to_lower()%>%
  str_replace_all(.,"\\+|&|@|\\/|!|;|,"," ")%>%
  str_replace_all(.,"by|the|of|in|on|to","")%>%str_split(.," ")
words=map(words,~.x[.x!=""])
word_count=map_dbl(words,~length(.x))
dat=dat%>%mutate(wcount=word_count)
ggplot(data=dat,mapping = aes(x=word_count,y=log(price)))+geom_point()+geom_smooth()
ggplot(data=dat,mapping = aes(x=word_count,y=log(1+number_of_reviews)))+geom_point()+geom_smooth()
```

```{r}
library(wordcloud)
names=dat$name%>%str_to_lower()%>%word()%>%str_replace_all(.,"\\+|@|\\/|!|;|,|\\*|\\(|\\)|:|-|_|¡|\\.|\\'|‘|’|\\'|\"|“|”|a|the","")
all_words=names[!names%in%stop_words]%>%table()
wordcloud(names(all_words),all_words,max.words = 100)
```

## model

- CAR/SAR
- hierachical model with spatial prior
- just hierachical model instead of using the lat/long

references:

http://www2.stat.duke.edu/~cr173/Sta444_Fa18/

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074178/pdf/nihms237255.pdf

https://www.google.com/search?q=spatial+prior+hierachical+model+r+package&oq=spatial+prior+hierachical+model+r+package&aqs=chrome..69i57.16517j0j7&sourceid=chrome&ie=UTF-8

pkg: HSAR, spBayes, CARBayes

```{r}
library("sf")
p=st_read("/Users/yunranchen/GoDuke/20Spring/STAT723CaseStudy/Case-Study-2-team-4/Neighborhood Tabulation Areas (NTA)/geo_export_c2bca37b-2a5a-4129-9a53-1ca377d98cb8.shp",quiet=TRUE)%>%tbl_df() %>% st_sf()
plot(select(p,ntacode))
# adjacency matrix of neighbourhoods
adj = st_touches(p, sparse=FALSE)
corrplot::corrplot(adj,method="color",type="full",tl.col="black",cl.pos = "n",)
# merge two dataset based on lat and long
dat.sf=st_as_sf(dat,coords = c("longitude","latitude"))
st_crs(dat.sf)=st_crs(p)
dat.p.int=st_intersects(dat.sf,p)
res_dat=st_join(dat.sf,p,join=st_intersects)
#save(res_dat,file="resultdataset.rdata")
plot(select(res_dat,ntaname))
```



